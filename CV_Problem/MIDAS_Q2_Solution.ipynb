{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assumptions -\n",
    "##### I assume dataset is present on the same path as code is present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import copy\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "from numpy import array\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_image.pkl\", 'rb') as fo:\n",
    "    train_data = pickle.load(fo, encoding='bytes')\n",
    "with open(\"train_label.pkl\", 'rb') as f1:\n",
    "    train_label = pickle.load(f1, encoding='bytes')\n",
    "with open(\"test_image.pkl\", 'rb') as f2:\n",
    "    test_data = pickle.load(f2, encoding='bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA with logistic \n",
    "##### Approach behind using PCA is only taking account of good fatures I used those eigen vector which have eigen energy 95%.\n",
    "##### After PCA I apply logistic regression which perform good, as comparison to other classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA function for dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA(data,dimension,eigen_energy):\n",
    "    m, n = data.shape  \n",
    "    s = np.cov(data.T)\n",
    "    eigen_val, eigen_vec = LA.eigh(s)         #to compute eigen value and eigen vector.\n",
    "    length = len(eigen_vec)                  #to compute eigen energy.\n",
    "    index = np.argsort(eigen_val)[::-1]      #determine index of eigen_val after sorted in desending order.\n",
    "    eigen_vec = eigen_vec[:,index]           #shift eigen_vec according to eigen_Val.\n",
    "    eigen_val[::-1].sort()                   #sort eigenval\n",
    "    new_eval=[]\n",
    "    new_evec=[]\n",
    "    if(eigen_energy>0):\n",
    "        temp=0\n",
    "        count=0\n",
    "        eigen_energy= sum(eigen_val)*(eigen_energy/100)\n",
    "        for i in range(len(eigen_val)):\n",
    "            temp=temp+eigen_val[i]\n",
    "            if(temp >  eigen_energy):\n",
    "                break\n",
    "            else:\n",
    "                count+=1\n",
    "                new_eval.append(eigen_val[i])\n",
    "                new_evec.append(eigen_vec[i])\n",
    "        new_evec = eigen_vec[:,:count]\n",
    "        new_evec=new_evec.T\n",
    "        result = (np.dot(new_evec, data.T)).T\n",
    "        return result, new_evec\n",
    "    else:\n",
    "        new_evec = eigen_vec[:,:dimension]\n",
    "        new_evec=new_evec.T\n",
    "    result = (np.dot(new_evec, data.T).T)\n",
    "    return result, new_evec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform PCA over Train and Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,pca_evec=PCA(np.array(train_data),0,95)\n",
    "train_data=train_data.tolist()\n",
    "test_data = ((np.dot(pca_evec, (np.array(test_data)).T).T)).tolist() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier method of Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(train_data,train_label,test_data,test_label):\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(train_data, train_label)\n",
    "    clf = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial').fit(train_data,train_label)\n",
    "    prediction =  clf.predict(test_data)\n",
    "    acc = clf.score(test_data,test_label)\n",
    "    parameter = clf.get_params()\n",
    "    return acc*100,parameter,clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform cross validation\n",
    "##### The reason for coss validation is that to train our model more precisely and I perform 5-fold and after which fold give best accuracy I take there parameters and predict the Testdata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold(temp_data,temp_label,fold_time):   \n",
    "    temp_data, temp_label = shuffle ((temp_data), (temp_label))\n",
    "    index_1=int(len(temp_data)/fold_time)\n",
    "\n",
    "    index_2=0\n",
    "    index_3=index_1\n",
    "    para=[] ; accuracy=[] ; clf_obj=[]\n",
    "    for i in range (0,fold_time):\n",
    "        test_data=[];test_label=[];train_data=[];train_label=[]\n",
    "       \n",
    "        test_data=temp_data[index_2:index_3]\n",
    "        test_label=temp_label[index_2:index_3]\n",
    "        index_2=index_1+index_2\n",
    "        index_3=index_1+index_3\n",
    "        \n",
    "        for j in range(len(temp_data)):\n",
    "            if temp_data[j] not in test_data:\n",
    "                train_data.append(temp_data[j])\n",
    "                train_label.append(temp_label[j])\n",
    "\n",
    "        \n",
    "        acc,pa,clf_obj_1=classifier(train_data,train_label,test_data,test_label)\n",
    "        print(\"Accuracy after fold \",i+1,\"is =\",acc)\n",
    "        para.append(pa)\n",
    "        accuracy.append(acc)\n",
    "        clf_obj.append(clf_obj_1)\n",
    "        \n",
    "    index = accuracy.index(max(accuracy))\n",
    "    print(\"MAX Accuracy across 5-fold :\",max(accuracy))\n",
    "    return para[index],clf_obj[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after fold  1 is = 81.375\n",
      "Accuracy after fold  2 is = 79.1875\n",
      "Accuracy after fold  3 is = 82.625\n",
      "Accuracy after fold  4 is = 80.25\n",
      "Accuracy after fold  5 is = 80.25\n",
      "MAX Accuracy across 5-fold : 82.625\n"
     ]
    }
   ],
   "source": [
    "p,c=fold(train_data,train_label,5)\n",
    "c.set_params(**p)\n",
    "prediction = c.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write out into csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic=[]\n",
    "count=0\n",
    "dic.append(['image_index','class'])\n",
    "for i in prediction:\n",
    "    d=[]\n",
    "    d.append(count)\n",
    "    d.append(i)\n",
    "    dic.append(d)\n",
    "    count+=1\n",
    "df = pd.DataFrame(dic)\n",
    "df.to_csv(\"Vikash_kumar_pandey.csv\", encoding='utf-8', index=False,header =False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
